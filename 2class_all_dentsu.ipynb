{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2class_all_dentsu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkrdmshr/colab/blob/master/2class_all_dentsu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "39dRe17wh1Su",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ローカルファイルを直接アップロードする\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qOyxTcUIozpg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ウェブサイトから直接ダウンロードする\n",
        " !wget http://www.cl.ecei.tohoku.ac.jp/~m-suzuki/jawiki_vector/data/20170201.tar.bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cp__vbt2ohVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -jxvf 20170201.tar.bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6-QgXRqEO51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ローカルファイルを直接アップロードする\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ei9FmcKZKg4r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.layers import merge, Embedding, Flatten, Dense, Input, Bidirectional, Conv1D, MaxPooling1D, Multiply, Permute, Reshape, Concatenate\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZADqEatODJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  # pickleロード用の関数\n",
        "  def load_pickle(file_name):\n",
        "    # loading\n",
        "      with open(file_name+'.pickle', 'rb') as handle:\n",
        "          return pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M60gaBBGjUXT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_embed(tokenizer):\n",
        "    index2word = {v:k for k, v in tokenizer.word_index.items()}\n",
        "    word_index = tokenizer.word_index\n",
        "    num_words = len(word_index)\n",
        "    embedding_matrix = np.zeros((num_words+1, 200))\n",
        "    for word, i in word_index.items():\n",
        "        if word in embeddings_model.index2word:\n",
        "            try:\n",
        "                embedding_matrix[i] = embeddings_model[word]\n",
        "            except:\n",
        "                None\n",
        "    return num_words, embedding_matrix\n",
        "  \n",
        "  \n",
        "def build_network_CNN_bi_lstm_attention(X_shape,num_words, embedding_matrix ,num_class):\n",
        "    lstm_dim = 200\n",
        "\n",
        "    '''embeddingをconcatしてCNNからのLSTMからのattention'''\n",
        "\n",
        "    inputs = Input(shape=(X_shape,))\n",
        "    embedding = Embedding(input_dim=num_words+1,output_dim=lstm_dim,weights=[embedding_matrix],trainable=False)(inputs)\n",
        "    CNN_out = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(embedding)\n",
        "    pool_out =MaxPooling1D(pool_size=2)(CNN_out)\n",
        "    lstm_out = Bidirectional(LSTM(lstm_dim, dropout=0.2, recurrent_dropout=0.2,return_sequences=True))(pool_out)\n",
        "    attention_mul = attention_3d_block(lstm_out,int(pool_out.shape[1]))\n",
        "    attention_flatten_mul = Flatten()(attention_mul)\n",
        "    output = Dense(num_class, activation='sigmoid')(attention_flatten_mul)\n",
        "    model = Model(inputs, output=output)\n",
        "    return model\n",
        "  \n",
        "def attention_3d_block(inputs,time_steps):\n",
        "    TIME_STEPS = time_steps\n",
        "    # if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
        "    SINGLE_ATTENTION_VECTOR = False\n",
        "\n",
        "    input_dim = int(inputs.shape[2])\n",
        "    a = Permute((2, 1))(inputs)\n",
        "    a = Reshape((input_dim,TIME_STEPS))(a)\n",
        "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
        "    if SINGLE_ATTENTION_VECTOR:\n",
        "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
        "        a = RepeatVector(input_dim)(a)\n",
        "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
        "\n",
        "    output_attention_mul = Multiply(name='attention_mul')([inputs, a_probs])\n",
        "    return output_attention_mul   \n",
        "\n",
        "  \n",
        "def build_network_wrapper(shapes,words_list,embed_weights):\n",
        "    model = build_network_CNN_bi_lstm_attention(shapes,words_list,embed_weights,3)\n",
        "    return model\n",
        "\n",
        "\n",
        "embeddings_model = KeyedVectors.load_word2vec_format(\"entity_vector/entity_vector.model.bin\", binary= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oDRg8hcnKk15",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#データのロード\n",
        "\n",
        "x_train = np.load('x_train.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "x_val = np.load('x_val.npy')\n",
        "y_val = np.load('y_val.npy')\n",
        "brand_train = np.load('brand_train.npy')\n",
        "brand_val = np.load('brand_val.npy')\n",
        "\n",
        "#tokenizerのロード\n",
        "file_name = '2class_all'\n",
        "tokenizers = load_pickle(file_name)\n",
        "\n",
        "#モデルの構築\n",
        "num_words, embedding_matrix = get_embed(tokenizers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqHbUMcUSHmL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = build_network_CNN_bi_lstm_attention(x_train.shape[1], num_words, embedding_matrix, 2)\n",
        "model.compile(optimizer='nadam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukvSZux9OkG4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習の重み\n",
        "class_weight = {0:0.50292848 ,1:85.86851852}\n",
        "\n",
        "#学習\n",
        "model.fit(x_train,y_train,\n",
        "              batch_size=32,\n",
        "              epochs=25,\n",
        "              verbose=1, \n",
        "              shuffle=True, \n",
        "              validation_data=(x_val,y_val),\n",
        "              class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wm_RyUj9R5iq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kTeh9i4tuJeb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-vGd0DtFuRR9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}